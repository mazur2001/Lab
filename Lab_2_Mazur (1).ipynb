{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b779523e",
      "metadata": {
        "id": "b779523e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b227c7",
      "metadata": {
        "id": "f2b227c7"
      },
      "outputs": [],
      "source": [
        "num_classes = 10 \n",
        "num_features = 784 \n",
        "\n",
        "learning_rate = 0.001 \n",
        "training_steps = 3000 \n",
        "batch_size = 256 \n",
        "display_step = 100 \n",
        "\n",
        "n_hidden_1 = 128 \n",
        "n_hidden_2 = 256 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15789643",
      "metadata": {
        "id": "15789643"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b6bdb6",
      "metadata": {
        "id": "e1b6bdb6"
      },
      "outputs": [],
      "source": [
        "class DenseLayer(tf.Module):\n",
        "    def __init__(self, in_features, out_features, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.w = tf.Variable(\n",
        "            tf.random.normal([in_features, out_features]), name=\"w\"\n",
        "        )\n",
        "        self.b = tf.Variable(tf.zeros([out_features]), name=\"b\")\n",
        "\n",
        "    def __call__(self, x, activation=0):\n",
        "        y = tf.matmul(x, self.w) + self.b\n",
        "        if activation !=0:\n",
        "            return tf.nn.softmax(y)\n",
        "        else:\n",
        "            return tf.nn.sigmoid(y)\n",
        "\n",
        "class NN(tf.Module):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.layer_1 = DenseLayer(in_features=num_features, out_features=n_hidden_1)\n",
        "        self.layer_2 = DenseLayer(in_features=n_hidden_1, out_features=n_hidden_2)\n",
        "        self.layer_3 = DenseLayer(in_features=n_hidden_2, out_features=num_classes)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x1 = self.layer_1(x, activation=0)\n",
        "        x2 = self.layer_2(x1, activation=0)\n",
        "        x3 = self.layer_3(x2, activation=1)\n",
        "        return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec891ac0",
      "metadata": {
        "id": "ec891ac0"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(y_pred, y_true):\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    acc = tf.metrics.Accuracy()\n",
        "    acc.update_state(y_true, tf.argmax(y_pred, axis=1))\n",
        "    return acc.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e9d81d",
      "metadata": {
        "id": "d4e9d81d"
      },
      "outputs": [],
      "source": [
        "neural_net = NN(name=\"mnist\")\n",
        "\n",
        "def train(nn, input_x, output_y):\n",
        "  \n",
        "    optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = neural_net(input_x)\n",
        "        loss = cross_entropy(pred, output_y)\n",
        "        \n",
        "    # Створимо список параметрів, що оптимізуються.\n",
        "        trainable_variables = nn.trainable_variables\n",
        "    # Обчислимо за ними значення градієнта\n",
        "        gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Модифікуємо параметри\n",
        "        optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43415dba",
      "metadata": {
        "id": "43415dba"
      },
      "outputs": [],
      "source": [
        "# Тренування мережі\n",
        "\n",
        "loss_history = [] \n",
        "accuracy_history = [] \n",
        "\n",
        "# У цьому циклі ми будемо проводити навчання нейронної мережі\n",
        "# з тренувального датасету train_data вийміть випадкову підмножину, на якій\n",
        "# відбудеться тренування. Використовуйте метод take, доступний для тренувального датасету.\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps)):\n",
        "    # Оновлюємо ваги нейронної мережі\n",
        "    train(neural_net, batch_x, batch_y)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        pred = neural_net(batch_x)\n",
        "        current_loss = cross_entropy(pred, batch_y)\n",
        "        loss_history.append(current_loss)\n",
        "        \n",
        "        current_accuracy = accuracy(pred, batch_y)\n",
        "        accuracy_history.append(current_accuracy)\n",
        "        print(f\"Step: {step}, Loss: {current_loss}, Accuracy: {current_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfda4f6",
      "metadata": {
        "id": "9dfda4f6"
      },
      "outputs": [],
      "source": [
        "# Виведіть графіки залежності зміни точності та втрат від кроку\n",
        "# Якщо все зроблено правильно, то точність має зростати, а втрати зменшуватися\n",
        "    \n",
        "fig, axs = plt.subplots(figsize=(16, 10))\n",
        "axs.plot(loss_history, 'r', label='loss', linestyle=\":\")\n",
        "axs.legend()\n",
        "axs2=axs.twinx()\n",
        "axs2.plot(accuracy_history, 'b', label='accuracy', linestyle=\":\")\n",
        "plt.legend()\n",
        "    \n",
        "plt.title('Залежності зміни точності та втрат від кроку', fontsize=20, color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a336c1",
      "metadata": {
        "id": "b7a336c1"
      },
      "outputs": [],
      "source": [
        "# Обчисліть точність навченої нейромережі\n",
        "\n",
        "neural_net_accuracy = accuracy(neural_net(x_train), y_train)\n",
        "print(f\"Accuracy: {neural_net_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ecb01de",
      "metadata": {
        "id": "5ecb01de"
      },
      "outputs": [],
      "source": [
        "# Протестуємо навчену нейромережу на 10 зображеннях. З тестової вибірки візьміть 5\n",
        "# випадкових зображень і передайте їх у нейронну мережу.\n",
        "# Виведіть зображення та випишіть поруч відповідь нейромережі.\n",
        "# Зробіть висновок про те, чи помиляється ваша нейронна мережа і якщо так, то як часто?\n",
        "test_img = np.random.permutation(x_test.shape[0])[:10]\n",
        "y_test_true = y_test[test_img]\n",
        "pred_data = [np.argmax(x) for x in neural_net(x_test[test_img])]\n",
        "plt.figure(figsize=(16,6))\n",
        "for i in range(10):\n",
        "    print(f\"True: {y_test_true[i]} Predict: {pred_data[i]} {True if y_test_true[i] - pred_data[i] == 0 else False}\")\n",
        "    plt.subplot(1, 10, (i + 1))\n",
        "    plt.imshow(x_test[test_img[i]].reshape(28, 28), cmap='Orange')\n",
        "    plt.text(x=10, y=-10, s=pred_data[i], fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}